# https://github.com/TaoHuang2018/Neighbor2Neighbor/blob/main/train.py

import torch

operation_seed_counter = 0

# def get_generator():
#     global operation_seed_counter
#     operation_seed_counter += 1
#     g_cuda_generator = torch.Generator(device="cuda")
#     g_cuda_generator.manual_seed(operation_seed_counter)
#     return g_cuda_generator
def get_generator(device):
    global operation_seed_counter
    operation_seed_counter += 1
    g_cuda_generator = torch.Generator(device=device)
    g_cuda_generator.manual_seed(operation_seed_counter)
    return g_cuda_generator

def space_to_depth(x, block_size):
    n, c, h, w = x.size()
    unfolded_x = torch.nn.functional.unfold(x, block_size, stride=block_size)
    return unfolded_x.view(n, c * block_size**2, h // block_size,
                           w // block_size)

# def generate_mask_pair(img):
#     # prepare masks (N x C x H/2 x W/2)
#     n, c, h, w = img.shape
#     mask1 = torch.zeros(size=(n * h // 2 * w // 2 * 4, ),
#                         dtype=torch.bool,
#                         device=img.device)
#     mask2 = torch.zeros(size=(n * h // 2 * w // 2 * 4, ),
#                         dtype=torch.bool,
#                         device=img.device)
#     # prepare random mask pairs
#     idx_pair = torch.tensor(
#         [[0, 1], [0, 2], [1, 3], [2, 3], [1, 0], [2, 0], [3, 1], [3, 2]],
#         dtype=torch.int64,
#         device=img.device)
#     rd_idx = torch.zeros(size=(n * h // 2 * w // 2, ),
#                          dtype=torch.int64,
#                          device=img.device)
#     torch.randint(low=0,
#                   high=8,
#                   size=(n * h // 2 * w // 2, ),
#                   generator=get_generator(),
#                   out=rd_idx)
#     rd_pair_idx = idx_pair[rd_idx]
#     rd_pair_idx += torch.arange(start=0,
#                                 end=n * h // 2 * w // 2 * 4,
#                                 step=4,
#                                 dtype=torch.int64,
#                                 device=img.device).reshape(-1, 1)
#     # get masks
#     mask1[rd_pair_idx[:, 0]] = 1
#     mask2[rd_pair_idx[:, 1]] = 1
#     return mask1, mask2
def generate_mask_pair(img):
    # prepare masks (N x C x H/2 x W/2)
    n, c, h, w = img.shape
    mask1 = torch.zeros(size=(n * h // 2 * w // 2 * 4, ),
                        dtype=torch.bool,
                        device=img.device)
    mask2 = torch.zeros(size=(n * h // 2 * w // 2 * 4, ),
                        dtype=torch.bool,
                        device=img.device)
    # prepare random mask pairs
    idx_pair = torch.tensor(
        [[0, 1], [0, 2], [1, 3], [2, 3], [1, 0], [2, 0], [3, 1], [3, 2]],
        dtype=torch.int64,
        device=img.device)
    rd_idx = torch.zeros(size=(n * h // 2 * w // 2, ),
                         dtype=torch.int64,
                         device=img.device)
    
    # Ensure the generator is on the correct device
    generator = get_generator(img.device)
    
    torch.randint(low=0,
                  high=8,
                  size=(n * h // 2 * w // 2, ),
                  generator=generator,
                  out=rd_idx)
    
    rd_pair_idx = idx_pair[rd_idx]
    rd_pair_idx += torch.arange(start=0,
                                end=n * h // 2 * w // 2 * 4,
                                step=4,
                                dtype=torch.int64,
                                device=img.device).reshape(-1, 1)
    
    # get masks
    mask1[rd_pair_idx[:, 0]] = 1
    mask2[rd_pair_idx[:, 1]] = 1
    return mask1, mask2
def generate_subimages(img, mask):
    n, c, h, w = img.shape
    subimage = torch.zeros(n,
                           c,
                           h // 2,
                           w // 2,
                           dtype=img.dtype,
                           layout=img.layout,
                           device=img.device)
    # per channel
    for i in range(c):
        img_per_channel = space_to_depth(img[:, i:i + 1, :, :], block_size=2)
        img_per_channel = img_per_channel.permute(0, 2, 3, 1).reshape(-1)
        subimage[:, i:i + 1, :, :] = img_per_channel[mask].reshape(
            n, h // 2, w // 2, 1).permute(0, 3, 1, 2)
    return subimage

def loss_func(noisy, network, tmp_iter, max_iter):
    # mask1, mask2 = generate_mask_pair(noisy)
    mask1, mask2 = generate_mask_pair(noisy.to(noisy.device))  # Ensure the mask is generated on the same device

    noisy_sub1 = generate_subimages(noisy, mask1)
    noisy_sub2 = generate_subimages(noisy, mask2)
    with torch.no_grad():
        noisy_denoised = network(noisy).clip(0, 1)
    noisy_sub1_denoised = generate_subimages(noisy_denoised, mask1)
    noisy_sub2_denoised = generate_subimages(noisy_denoised, mask2)

    noisy_output = network(noisy_sub1).clip(0, 1)
    noisy_target = noisy_sub2
    Lambda = tmp_iter / max_iter * 0.1
    diff = noisy_output - noisy_target
    exp_diff = noisy_sub1_denoised - noisy_sub2_denoised

    loss1 = torch.mean(diff**2)
    loss2 = Lambda * torch.mean((diff - exp_diff)**2)
    loss_all = 1.0 * loss1 + 1.0 * loss2

    return loss_all